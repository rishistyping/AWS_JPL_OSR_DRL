import json
import os
import time
import numpy as np
from PIL import Image
from rl_coach.agents.clipped_ppo_agent import ClippedPPOAgentParameters
from rl_coach.base_parameters import MiddlewareScheme, EmbedderScheme, VisualizationParameters, PresetValidationParameters, DistributedCoachSynchronizationType
from rl_coach.core_types import TrainingSteps, EnvironmentEpisodes, EnvironmentSteps, AlwaysDumpFilter, ObservationType
from rl_coach.environments.gym_environment import GymVectorEnvironment
from rl_coach.exploration_policies.categorical import CategoricalParameters
from rl_coach.exploration_policies.e_greedy import EGreedyParameters
from rl_coach.filters.filter import InputFilter
from rl_coach.filters.observation.observation_filter import ObservationFilter
from rl_coach.filters.observation.observation_rescale_to_size_filter import ObservationRescaleToSizeFilter
from rl_coach.filters.observation.observation_rgb_to_y_filter import ObservationRGBToYFilter
from rl_coach.filters.observation.observation_stacking_filter import ObservationStackingFilter
from rl_coach.filters.observation.observation_to_uint8_filter import ObservationToUInt8Filter
from rl_coach.graph_managers.basic_rl_graph_manager import BasicRLGraphManager
from rl_coach.graph_managers.graph_manager import ScheduleParameters
from rl_coach.schedules import LinearSchedule
from rl_coach.spaces import ObservationSpace, ImageObservationSpace
#import tensorflow as tf

class ObservationColorPerturbation(ObservationFilter):
    """
    Adds image color perturbation as described in https://arxiv.org/pdf/1911.01562.pdf
    """
    def __init__(self, probability, dump_images=False):
        super().__init__()
        self.sess = None
        self.probability = probability
        self.hue_max_delta = 0.5                # hue will be multiplied by (1.0 +/- hue_max_delta)
        self.min_max_saturation = [0.0, 1.0]    # will be set as absolute saturation for image in this range
        self.min_max_contrast = [0.0, 1.0]      # will be set as absolute contrast for image within this range
        self.brightness_max_delta = 0.5         # brightness will be multiplied by (1.0 +/ brightness_max_delta)
        self.dump_images = dump_images

    def set_session(self, session):
        self.sess = session

    def validate_input_observation_space(self, input_observation_space: ObservationSpace):
        if input_observation_space.num_dimensions != 3:
            raise ValueError("The color purturbation filter only applies to image observations where the number of dimensions is"
                             "3 (RGB). The number of dimensions defined for the input observation was {}"
                             .format(input_observation_space.num_dimensions))
        if input_observation_space.shape[-1] != 3:
            raise ValueError("The observation space is expected to have 3 channels in the 1st dimension. The number of "
                             "dimensions received is {}".format(input_observation_space.shape[-1]))

#    def filter(self, observation: ObservationType, update_internal_state: bool=True) -> ObservationType:
#        image_tensor = tf.convert_to_tensor(observation)
#
#        # hue
#        if np.random.choice((True,False), p=(self.probability,1.0 - self.probability)):
#            image_tensor = tf.image.random_hue(image_tensor, self.hue_max_delta)
#        # saturation
#        if np.random.choice((True,False), p=(self.probability,1.0 - self.probability)):
#            image_tensor = tf.image.random_saturation(image_tensor, self.min_max_saturation[0], self.min_max_saturation[1])
#        # contrast
#        if np.random.choice((True,False), p=(self.probability,1.0 - self.probability)):
#            image_tensor = tf.image.random_contrast(image_tensor, self.min_max_contrast[0], self.min_max_contrast[1])
#        # brightness
#        if np.random.choice((True,False), p=(self.probability,1.0 - self.probability)):
#            image_tensor = tf.image.random_brightness(image_tensor, self.brightness_max_delta)
#
#        # Tensor evaluation always returns shape (160,120,3,1,1)
#        evaluated = image_tensor.eval(session=self.sess)
#
#        if self.dump_images:
#            fname = 'color_perturb_filter_%f' % time.time()
#            np.save(os.path.join("/opt/ml/model", fname), np.array(evaluated))
#
#        return evaluated

    def filter(self, observation: ObservationType, update_internal_state: bool=True) -> ObservationType:
        changes = list()
        image = Image.fromarray(observation, mode='RGB')

        # contrast: multiplier in RGB space
        if np.random.choice(2, p=(1.0 - self.probability, self.probability)):
            changes.append('Contrast')
            contrast_mult = np.random.uniform(0.5,1.5)
            new_contrast_array = np.array(image, 'float') * contrast_mult
            new_contrast_array = np.clip(new_contrast_array, 0, 255)
            image = Image.fromarray(new_contrast_array.astype('uint8'))

        # HSV conversion
        hsv_image = image.convert(mode='HSV')
        h,s,v = hsv_image.split()

        # hue: rotation
        if np.random.choice(2, p=(1.0 - self.probability, self.probability)):
            changes.append("Hue")
            # PIL uses 0..255 for Hue range
            hue_delta = np.random.randint(0,255)
            hue_array = np.array(h, dtype='float') # convert to flow to allow overflow
            new_hue_array = (hue_array + hue_delta) % 256
            h = Image.fromarray(new_hue_array.astype('uint8'), 'L')

        # saturation: multiplier
        if np.random.choice(2, p=(1.0 - self.probability, self.probability)):
            changes.append("Saturation")
            sat_mult = np.random.uniform(0.0,1.0)
            sat_array = np.array(s, dtype='float')
            new_sat_array = sat_array * sat_mult
            new_sat_array = np.clip(new_sat_array, 0, 255)
            s = Image.fromarray(new_sat_array.astype('uint8'), 'L')

        # brightness: delta
        if np.random.choice(2, p=(1.0 - self.probability, self.probability)):
            changes.append("Brightness")
            bright_delta = np.random.randint(-127,127)
            bright_array = np.array(v, dtype='float')
            new_bright_array = bright_array + bright_delta
            new_bright_array = np.clip(new_bright_array, 0, 255)
            v = Image.fromarray(new_bright_array.astype('uint8'), 'L')

        final_image = Image.merge('HSV', (h,s,v))
        final_image = final_image.convert(mode='RGB')

        if self.dump_images:
            # hide the print statement here so its only invoked when we don't care about performance
            print("ObservationColorPerturbation Changes: %s" % ','.join(changes))
            fname = 'color_perturb_filter_%f' % time.time()
            np.save(os.path.join("/opt/ml/model", fname), np.array(final_image))

        return np.array(final_image)


def get_graph_manager(**hp_dict):
    ####################
    # All Default Parameters #
    ####################
    params = {}
    params["batch_size"] = int(hp_dict.get("batch_size", 64))
    params["num_epochs"] = int(hp_dict.get("num_epochs", 10))
    params["stack_size"] = int(hp_dict.get("stack_size", 1))
    params["lr"] = float(hp_dict.get("lr", 0.0003))
    params["lr_decay_rate"] = float(hp_dict.get("lr_decay_rate", 0))
    params["lr_decay_steps"] = float(hp_dict.get("lr_decay_steps", 0))
    params["exploration_type"] = (hp_dict.get("exploration_type", "categorical")).lower()
    params["e_greedy_value"] = float(hp_dict.get("e_greedy_value", .05))
    params["epsilon_steps"] = int(hp_dict.get("epsilon_steps", 10000))
    params["beta_entropy"] = float(hp_dict.get("beta_entropy", .01))
    params["discount_factor"] = float(hp_dict.get("discount_factor", .999))
    params["loss_type"] = hp_dict.get("loss_type", "Mean squared error").lower()
    params["num_episodes_between_training"] = int(hp_dict.get("num_episodes_between_training", 20))
    params["term_cond_max_episodes"] = int(hp_dict.get("term_cond_max_episodes", 100000))
    params["term_cond_avg_score"] = float(hp_dict.get("term_cond_avg_score", 100000))
    params["tensorboard"] = hp_dict.get("tensorboard", False)
    params["dump_mp4"] = hp_dict.get("dump_mp4", False)
    params["dump_gifs"] = hp_dict.get("dump_gifs", False)

    params_json = json.dumps(params, indent=2, sort_keys=True)
    print("Using the following hyper-parameters", params_json, sep='\n')

    ####################
    # Graph Scheduling #
    ####################
    schedule_params = ScheduleParameters()
    schedule_params.improve_steps = TrainingSteps(params["term_cond_max_episodes"])
    schedule_params.steps_between_evaluation_periods = EnvironmentEpisodes(40)
    schedule_params.evaluation_steps = EnvironmentEpisodes(5)
    schedule_params.heatup_steps = EnvironmentSteps(0)

    #########
    # Agent #
    #########
    agent_params = ClippedPPOAgentParameters()

    agent_params.network_wrappers['main'].learning_rate = params["lr"]
    agent_params.network_wrappers['main'].learning_rate_decay_rate = params["lr_decay_rate"]
    agent_params.network_wrappers['main'].learning_rate_decay_steps = params["lr_decay_steps"]
    agent_params.network_wrappers['main'].input_embedders_parameters['observation'].activation_function = 'relu'
    # Replace the default CNN with single layer Conv2d(32, 3, 1)
#   agent_params.network_wrappers['main'].input_embedders_parameters['observation'].scheme = EmbedderScheme.Shallow

#   agent_params.network_wrappers['main'].input_embedders_parameters['observation'].dropout_rate = 0.3
    agent_params.network_wrappers['main'].middleware_parameters.activation_function = 'relu'
#   agent_params.network_wrappers['main'].middleware_parameters.scheme = MiddlewareScheme.Shallow
#   agent_params.network_wrappers['main'].middleware_parameters.dropout_rate = 0.3
    agent_params.network_wrappers['main'].batch_size = params["batch_size"]
    agent_params.network_wrappers['main'].optimizer_epsilon = 1e-5
    agent_params.network_wrappers['main'].adam_optimizer_beta2 = 0.999
#   agent_params.network_wrappers['main'].l2_regularization = 2e-5

    if params["loss_type"] == "huber":
        agent_params.network_wrappers['main'].replace_mse_with_huber_loss = True

    agent_params.algorithm.clip_likelihood_ratio_using_epsilon = 0.2
    agent_params.algorithm.clipping_decay_schedule = LinearSchedule(1.0, 0, 1000000)
    agent_params.algorithm.beta_entropy = params["beta_entropy"]
    agent_params.algorithm.gae_lambda = 0.95
    agent_params.algorithm.discount = params["discount_factor"]
    agent_params.algorithm.optimization_epochs = params["num_epochs"]
    agent_params.algorithm.estimate_state_value_using_gae = True
    agent_params.algorithm.num_steps_between_copying_online_weights_to_target = EnvironmentEpisodes(
        params["num_episodes_between_training"])
    agent_params.algorithm.num_consecutive_playing_steps = EnvironmentEpisodes(params["num_episodes_between_training"])

    agent_params.algorithm.distributed_coach_synchronization_type = DistributedCoachSynchronizationType.SYNC

    if params["exploration_type"] == "categorical":
        agent_params.exploration = CategoricalParameters()
    else:
        agent_params.exploration = EGreedyParameters()
        agent_params.exploration.epsilon_schedule = LinearSchedule(1.0,
                                                                   params["e_greedy_value"],
                                                                   params["epsilon_steps"])

    ###############
    # Environment #
    ###############
    DeepRacerInputFilter = InputFilter(is_a_reference_filter=True)
    # Add an observation image pertubation for many aspects
#   DeepRacerInputFilter.add_observation_filter('observation', 'perturb_color', ObservationColorPerturbation(0.2))
    # Rescale to much smaller input when using shallow networks to avoid OOM
#   DeepRacerInputFilter.add_observation_filter('observation', 'rescaling',
#                                           ObservationRescaleToSizeFilter(ImageObservationSpace(np.array([84, 84, 3]),
#                                                                                            high=255)))
    DeepRacerInputFilter.add_observation_filter('observation', 'to_grayscale', ObservationRGBToYFilter())
    DeepRacerInputFilter.add_observation_filter('observation', 'to_uint8', ObservationToUInt8Filter(0, 255))
    DeepRacerInputFilter.add_observation_filter('observation', 'stacking',
                                                  ObservationStackingFilter(params["stack_size"]))

    env_params = GymVectorEnvironment()
    env_params.default_input_filter = DeepRacerInputFilter
    env_params.level = 'DeepRacerRacetrackCustomActionSpaceEnv-v0'

    vis_params = VisualizationParameters()
    vis_params.tensorboard = params["tensorboard"]
    vis_params.dump_mp4 = params["dump_mp4"]
    vis_params.dump_gifs = params["dump_gifs"]
    # AlwaysDumpFilter, MaxDumpFilter, EveryNEpisodesDumpFilter, SelectedPhaseOnlyDumpFilter
    vis_params.video_dump_filters = [AlwaysDumpFilter()]

    ########
    # Test #
    ########
    preset_validation_params = PresetValidationParameters()
    preset_validation_params.test = True
    preset_validation_params.min_reward_threshold = 400
    preset_validation_params.max_episodes_to_achieve_reward = 10000

    graph_manager = BasicRLGraphManager(agent_params=agent_params, env_params=env_params,
                                        schedule_params=schedule_params, vis_params=vis_params,
                                        preset_validation_params=preset_validation_params)
    return graph_manager, params_json
